{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "321c117d-ea12-494c-a54f-56f85b9b5cc0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: np.str_(\"Geio de otras fimpatias ) y ‘DED ICATORIA\\ntan {uyo,que'a nadie deve Iq EN LOS. CONSEJOS\\n\\na que dexd a fus hijo, y hija\\n\\n| mayotes vna gran Seflorap 3. sl\\ndeftos Reynos de E fpaiig,\\n\\n: |\\n\\n}\\n|\\n\\nl\\n\\ntos fe ocultd fa\\nnombre.\\n\\nferuirle cOvna Cartilla paral\\ninfiruyr nines Nobles. Que\\nhalle al lado deftos papeles\\ncon la milma difpefici ;\\nshih: oe yi ficion, ¥ VL a los hijos fus Pa-\\n©cOX Con Igna cuydado, idres, y por el que principalmente\\nCapellan deV.S. | | {ellos les pueden quedar obligados;\\n\\nFr. Pedro Enrrique Paftor| defleando yo cumplir en efto la par\\njoerg i ve que me toca, y executaros en la\\nrouincial. P .\\n’ vueltra, no aniendofe feruido nuef-|\\nahah seh elects taeed a a. ca\\n\\nA tro\\n\\n\")",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m train_input_length \u001b[38;5;241m=\u001b[39m train_input_length\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint64\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m training_img \u001b[38;5;241m=\u001b[39m training_img\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m train_padded_txt \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_padded_txt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfloat32\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(train_label_length\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(train_input_length\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: np.str_(\"Geio de otras fimpatias ) y ‘DED ICATORIA\\ntan {uyo,que'a nadie deve Iq EN LOS. CONSEJOS\\n\\na que dexd a fus hijo, y hija\\n\\n| mayotes vna gran Seflorap 3. sl\\ndeftos Reynos de E fpaiig,\\n\\n: |\\n\\n}\\n|\\n\\nl\\n\\ntos fe ocultd fa\\nnombre.\\n\\nferuirle cOvna Cartilla paral\\ninfiruyr nines Nobles. Que\\nhalle al lado deftos papeles\\ncon la milma difpefici ;\\nshih: oe yi ficion, ¥ VL a los hijos fus Pa-\\n©cOX Con Igna cuydado, idres, y por el que principalmente\\nCapellan deV.S. | | {ellos les pueden quedar obligados;\\n\\nFr. Pedro Enrrique Paftor| defleando yo cumplir en efto la par\\njoerg i ve que me toca, y executaros en la\\nrouincial. P .\\n’ vueltra, no aniendofe feruido nuef-|\\nahah seh elects taeed a a. ca\\n\\nA tro\\n\\n\")"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_label_length = train_label_length.astype('float32')\n",
    "train_input_length = train_input_length.astype('int64')\n",
    "training_img = training_img.astype('float32')\n",
    "train_padded_txt = train_padded_txt.astype('float32')\n",
    "\n",
    "\n",
    "print(train_label_length.shape)\n",
    "print(train_input_length.shape)\n",
    "print(training_img.shape)\n",
    "print(train_padded_txt.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc8d042-ca91-4f7d-97c9-31cde1093de2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9160d659-63fb-4ba5-9bbd-255272108d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Lambda, Conv2D, Dropout, MaxPooling2D, BatchNormalization, Bidirectional, LSTM, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Load data\n",
    "train_label_length = np.load('train_label_length.npy')\n",
    "train_input_length = np.load('train_input_length.npy')\n",
    "training_img = np.load('training_img.npy')\n",
    "train_padded_txt = np.load('train_padded_txt.npy')\n",
    "max_label_len = np.load('max_label_len.npy').item()\n",
    "\n",
    "# Define character list\n",
    "char_list = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\"\n",
    "char_list_length = len(char_list) + 1  # +1 for CTC blank character\n",
    "\n",
    "# Model architecture\n",
    "inputs = Input(shape=(32, 128, 1), name=\"image_input\")\n",
    "normalized = Lambda(lambda x: x / 255.0, name=\"normalization_layer\")(inputs)\n",
    "\n",
    "conv_1 = Conv2D(16, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(normalized)\n",
    "conv_1 = Dropout(0.25)(conv_1)\n",
    "conv_1 = Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(conv_1)\n",
    "pool_1 = MaxPooling2D(pool_size=(2, 2), strides=2)(conv_1)\n",
    "\n",
    "conv_2 = Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(pool_1)\n",
    "conv_2 = BatchNormalization()(conv_2)\n",
    "conv_2 = Dropout(0.25)(conv_2)\n",
    "conv_2 = Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(conv_2)\n",
    "pool_2 = MaxPooling2D(pool_size=(2, 2), strides=2)(conv_2)\n",
    "\n",
    "conv_3 = Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(pool_2)\n",
    "conv_3 = BatchNormalization()(conv_3)\n",
    "conv_3 = Dropout(0.25)(conv_3)\n",
    "conv_3 = Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(conv_3)\n",
    "\n",
    "conv_4 = Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(conv_3)\n",
    "pool_4 = MaxPooling2D(pool_size=(2, 1))(conv_4)\n",
    "\n",
    "conv_5 = Conv2D(256, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(pool_4)\n",
    "batch_norm_5 = BatchNormalization()(conv_5)\n",
    "\n",
    "conv_6 = Conv2D(256, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(batch_norm_5)\n",
    "batch_norm_6 = BatchNormalization()(conv_6)\n",
    "pool_6 = MaxPooling2D(pool_size=(2, 1))(batch_norm_6)\n",
    "\n",
    "conv_7 = Conv2D(512, (2,2), activation='relu', kernel_initializer='he_normal', padding='same')(pool_6)\n",
    "\n",
    "# Squeeze operation with explicit output shape\n",
    "squeezed = Lambda(\n",
    "    lambda x: tf.keras.backend.squeeze(x, axis=1),\n",
    "    output_shape=lambda input_shape: (input_shape[0], input_shape[2], input_shape[3])  # Define output shape\n",
    ")(conv_7)\n",
    "\n",
    "blstm_1 = Bidirectional(LSTM(128, return_sequences=True, dropout=0.2))(squeezed)\n",
    "blstm_2 = Bidirectional(LSTM(128, return_sequences=True, dropout=0.2))(blstm_1)\n",
    "\n",
    "blstm_1 = Bidirectional(LSTM(128, return_sequences=True, dropout=0.2))(squeezed)\n",
    "blstm_2 = Bidirectional(LSTM(128, return_sequences=True, dropout=0.2))(blstm_1)\n",
    "\n",
    "outputs = Dense(char_list_length, activation='softmax', name=\"output_layer\")(blstm_2)\n",
    "\n",
    "act_model = Model(inputs, outputs, name=\"OCR_Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8a98842-ec6c-41a4-9f10-4a7229a48cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "labels = Input(name='the_labels', shape=[None], dtype='float32')\n",
    "input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "\n",
    "loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([outputs, labels, input_length, label_length])\n",
    "\n",
    "model = Model(inputs=[inputs, labels, input_length, label_length], outputs=loss_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1deb2a3d-7ae5-425b-ba08-9d99149605fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=lambda y_true, y_pred: y_pred,\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31ee0fb5-9394-4d5b-a5f9-6474561a7e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"best_model.keras\"\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=filepath,\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    mode='auto'\n",
    ")\n",
    "\n",
    "class DisplayCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, training_img, train_padded_txt, char_list):\n",
    "        super().__init__()\n",
    "        self.training_img = training_img\n",
    "        self.train_padded_txt = train_padded_txt\n",
    "        self.char_list = char_list\n",
    "        self.num_samples = len(training_img)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.model.save('model.h5')\n",
    "        i = np.random.randint(self.num_samples)\n",
    "        # Assuming display function is defined elsewhere\n",
    "        display(self.training_img[i], self.train_padded_txt[i], self.model)\n",
    "\n",
    "callbacks_list = [\n",
    "    checkpoint,\n",
    "    DisplayCallback(training_img, train_padded_txt, char_list)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3957a970-aeb9-4049-9539-9e2fc9637ad3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid dtype: str60032",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m\n\u001b[1;32m      2\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage_input\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_img\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mthe_labels\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_padded_txt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_length\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_input_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel_length\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_label_length\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mctc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_label_len\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Dummy output\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.08\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks_list\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/renaissance/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/renaissance/lib/python3.9/site-packages/optree/ops.py:766\u001b[0m, in \u001b[0;36mtree_map\u001b[0;34m(func, tree, is_leaf, none_is_leaf, namespace, *rests)\u001b[0m\n\u001b[1;32m    764\u001b[0m leaves, treespec \u001b[38;5;241m=\u001b[39m _C\u001b[38;5;241m.\u001b[39mflatten(tree, is_leaf, none_is_leaf, namespace)\n\u001b[1;32m    765\u001b[0m flat_args \u001b[38;5;241m=\u001b[39m [leaves] \u001b[38;5;241m+\u001b[39m [treespec\u001b[38;5;241m.\u001b[39mflatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rests]\n\u001b[0;32m--> 766\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtreespec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflat_args\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid dtype: str60032"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 20\n",
    "\n",
    "model.fit(\n",
    "    x={\n",
    "        'image_input': training_img,\n",
    "        'the_labels': train_padded_txt,\n",
    "        'input_length': train_input_length,\n",
    "        'label_length': train_label_length\n",
    "    },\n",
    "    y={'ctc': np.zeros(max_label_len)},  # Dummy output\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.08,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dda3f180-f27e-4733-b079-2302602530a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Exception encountered when calling Lambda.call().\n\n\u001b[1mWe could not automatically infer the shape of the Lambda's output. Please specify the `output_shape` argument for this Lambda layer.\u001b[0m\n\nArguments received by Lambda.call():\n  • args=('<KerasTensor shape=(None, 2, 32, 512), dtype=float32, sparse=False, name=keras_tensor_176>',)\n  • kwargs={'mask': 'None'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 55\u001b[0m\n\u001b[1;32m     51\u001b[0m pool_6 \u001b[38;5;241m=\u001b[39m MaxPooling2D(pool_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))(batch_norm_6)\n\u001b[1;32m     53\u001b[0m conv_7 \u001b[38;5;241m=\u001b[39m Conv2D(\u001b[38;5;241m512\u001b[39m, (\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, kernel_initializer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhe_normal\u001b[39m\u001b[38;5;124m'\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m)(pool_6)\n\u001b[0;32m---> 55\u001b[0m squeezed \u001b[38;5;241m=\u001b[39m \u001b[43mLambda\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconv_7\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m blstm_1 \u001b[38;5;241m=\u001b[39m Bidirectional(LSTM(\u001b[38;5;241m128\u001b[39m, return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m))(squeezed)\n\u001b[1;32m     58\u001b[0m blstm_2 \u001b[38;5;241m=\u001b[39m Bidirectional(LSTM(\u001b[38;5;241m128\u001b[39m, return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m))(blstm_1)\n",
      "File \u001b[0;32m~/anaconda3/envs/renaissance/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/renaissance/lib/python3.9/site-packages/keras/src/layers/core/lambda_layer.py:95\u001b[0m, in \u001b[0;36mLambda.compute_output_shape\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mmap_structure(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mshape, output_spec)\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m---> 95\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m     96\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWe could not automatically infer the shape of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     97\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe Lambda\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms output. Please specify the `output_shape` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margument for this Lambda layer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     99\u001b[0m         )\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_shape):\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_shape(input_shape)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Exception encountered when calling Lambda.call().\n\n\u001b[1mWe could not automatically infer the shape of the Lambda's output. Please specify the `output_shape` argument for this Lambda layer.\u001b[0m\n\nArguments received by Lambda.call():\n  • args=('<KerasTensor shape=(None, 2, 32, 512), dtype=float32, sparse=False, name=keras_tensor_176>',)\n  • kwargs={'mask': 'None'}"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Lambda, Conv2D, Dropout, MaxPooling2D, BatchNormalization, Bidirectional, LSTM, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "import keras.backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Load data\n",
    "train_label_length = np.load('train_label_length.npy').astype('int64')\n",
    "train_input_length = np.load('train_input_length.npy').astype('int64')\n",
    "training_img = np.load('training_img.npy').astype('float32')\n",
    "train_padded_txt = np.load('train_padded_txt.npy').astype('float32')\n",
    "max_label_len = np.load('max_label_len.npy').item()\n",
    "\n",
    "# Define character list\n",
    "char_list = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\"\n",
    "char_list_length = len(char_list) + 1  # +1 for CTC blank character\n",
    "\n",
    "# Model architecture\n",
    "inputs = Input(shape=(32, 128, 1), name=\"image_input\")\n",
    "normalized = Lambda(lambda x: x / 255.0, name=\"normalization_layer\")(inputs)\n",
    "\n",
    "conv_1 = Conv2D(16, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(normalized)\n",
    "conv_1 = Dropout(0.25)(conv_1)\n",
    "conv_1 = Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(conv_1)\n",
    "pool_1 = MaxPooling2D(pool_size=(2, 2), strides=2)(conv_1)\n",
    "\n",
    "conv_2 = Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(pool_1)\n",
    "conv_2 = BatchNormalization()(conv_2)\n",
    "conv_2 = Dropout(0.25)(conv_2)\n",
    "conv_2 = Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(conv_2)\n",
    "pool_2 = MaxPooling2D(pool_size=(2, 2), strides=2)(conv_2)\n",
    "\n",
    "conv_3 = Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(pool_2)\n",
    "conv_3 = BatchNormalization()(conv_3)\n",
    "conv_3 = Dropout(0.25)(conv_3)\n",
    "conv_3 = Conv2D(32, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(conv_3)\n",
    "\n",
    "conv_4 = Conv2D(64, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(conv_3)\n",
    "pool_4 = MaxPooling2D(pool_size=(2, 1))(conv_4)\n",
    "\n",
    "conv_5 = Conv2D(256, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(pool_4)\n",
    "batch_norm_5 = BatchNormalization()(conv_5)\n",
    "\n",
    "conv_6 = Conv2D(256, (3,3), activation='relu', kernel_initializer='he_normal', padding='same')(batch_norm_5)\n",
    "batch_norm_6 = BatchNormalization()(conv_6)\n",
    "pool_6 = MaxPooling2D(pool_size=(2, 1))(batch_norm_6)\n",
    "\n",
    "conv_7 = Conv2D(512, (2,2), activation='relu', kernel_initializer='he_normal', padding='same')(pool_6)\n",
    "\n",
    "# Squeeze operation with explicit output shape\n",
    "squeezed = Lambda(\n",
    "    lambda x: tf.keras.backend.squeeze(x, axis=1),\n",
    "    output_shape=lambda input_shape: (input_shape[0], input_shape[2], input_shape[3])\n",
    ")(conv_7)\n",
    "\n",
    "blstm_1 = Bidirectional(LSTM(128, return_sequences=True, dropout=0.2))(squeezed)\n",
    "blstm_2 = Bidirectional(LSTM(128, return_sequences=True, dropout=0.2))(blstm_1)\n",
    "\n",
    "outputs = Dense(char_list_length, activation='softmax', name=\"output_layer\")(blstm_2)\n",
    "\n",
    "act_model = Model(inputs, outputs, name=\"OCR_Model\")\n",
    "\n",
    "# CTC loss function\n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "labels = Input(name='the_labels', shape=[None], dtype='float32')\n",
    "input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "\n",
    "loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([outputs, labels, input_length, label_length])\n",
    "\n",
    "model = Model(inputs=[inputs, labels, input_length, label_length], outputs=loss_out)\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    loss=lambda y_true, y_pred: y_pred,\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "filepath = \"best_model.keras\"\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=filepath,\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    mode='auto'\n",
    ")\n",
    "\n",
    "class DisplayCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, training_img, train_padded_txt, char_list):\n",
    "        super().__init__()\n",
    "        self.training_img = training_img\n",
    "        self.train_padded_txt = train_padded_txt\n",
    "        self.char_list = char_list\n",
    "        self.num_samples = len(training_img)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.model.save('model.h5')\n",
    "        i = np.random.randint(self.num_samples)\n",
    "        # Assuming display function is defined elsewhere\n",
    "        display(self.training_img[i], self.train_padded_txt[i], self.model)\n",
    "\n",
    "callbacks_list = [\n",
    "    checkpoint,\n",
    "    DisplayCallback(training_img, train_padded_txt, char_list)\n",
    "]\n",
    "\n",
    "# Training\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "\n",
    "model.fit(\n",
    "    x={\n",
    "        'image_input': training_img,\n",
    "        'the_labels': train_padded_txt,\n",
    "        'input_length': train_input_length,\n",
    "        'label_length': train_label_length\n",
    "    },\n",
    "    y={'ctc': np.zeros(max_label_len)},  # Dummy output\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.08,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks_list\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
